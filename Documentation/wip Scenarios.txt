Scenario 0
======================================================================
Description:
---------------------------
Scenario 0 is a kusto training scenario.
I tend to take my engineers through this scenario twice.

1st Run- I give them a run ID and we walk through everything we can find in Activity Runs and Custom Log Events 
together so they can get familiar with kusto and query writing.

2nd Run- I gven them a run ID, the below list of questions, and the kusto guide link from the TSG
and have them answer all the questions by looking through kusto themselves. And I help them with any questions
they might have about finding the data.


List of Questions:
---------------------------
	1. Pipeline Run ID                      
	2. Activity Run ID(s)
	3. How many activities did this pipeline have? What was its/their name(s)?                    
	4. Activity Type(s)                          
	5. Data Factory Name
	6. Subscription ID
	7. What Region the Pipeline Ran In
	8. For each activity, Self-Hosted Integration Runtime or Azure Integration Runtime
	9. For each activity, Successful or Failed
	10. Pipeline Start Time
	11. Pipeline End Time
	12. Has this Pipeline Run more than once? If so, how many times?
	 
For any one of the copy activities (in the original pipeline run):
	13. What kind of source?
	14. What kind of sink?
	15. Name of the source resource?
	16. Name of the sink resource?
	17. Were retries set on the pipeline? If so, how many?
	18. What Timeout is set on this pipeline?
	19. What was the path of the source data?
	20. What was the path of the sink data?

For one successful copy activity please answer the following:
	22. Activity Run ID
	23. How many files went through the activity? 
	24. What was the size of the data?
	25. Was parallelization used? If so, how much?
	26. How many DIUs were used?
	27. How long did the pipeline queue?
	28. How long did it read from the source?
	29. How long did it write to the sink?

For one failed copy activity please answer the following:
	30. Activity Run ID
	31. Successful or Failed
	32. How many files went through the activity? 
	33. What was the size of the data?
	34. Was parallelization used? If so, how much?
	35. How many DIUs were used?
	36. How long did the pipeline queue?
	37. How long did it read from the source?
	38. How long did it write to the sink?


Skills we're looking for:
---------------------------
Comfort with navigating kusto and kusto query skills.


Scenario 1
======================================================================
Description:
---------------------------
Unable to run copy pipeline between source folder and sink folder in the same ADLS Gen 1.
Get an ACL error on running the copy activity.

Customer Verbatim:
---------------------------
Pipeline Run Id: <PROVIDE PIPELINE RUN ID>

My copy pipeline is failing with this error - 
\"CREATE failed with error 0x83090aa2 (Forbidden. ACL verification failed. Either the resource does not exist or the user is not authorized to perform the requested operation.).
Can you help me fix it?

Solution:
---------------------------
Write permission is missing for the service principal on the output folder for the ADLS Gen 1 sink.
Adding this write permission will resolve the issue.


Skills we're looking for:
---------------------------
1. In the FQR(First Quality Response) email they should provide a link to the documentation for the Azure Data Lake Store linked service
OR
The link for Azure Data lake Store permissions, as they should be able to tell this is the problem from the get-go.

2. Once they have provided this information, get them into a call and have them walk you through the steps to fix it themselves.

3. They could also choose to 'bring in' the Azure Data Lake store team, where they need to write a collab task explaining the issue,
and then assign the collab to you. Expect to have error timestamp and name of ADLS in the collab task.
Then you provide the above information as if you were from ADLS team.

Still have the engineer guide the customer through the process of setting the permissions even after having been given the right answer.

Scenario 2
======================================================================
Description:
---------------------------
Blob store linked service is unable to connect.
No pipeline is running, this is just a failing linked service.


Customer Verbatim:
---------------------------

Error message: <PROVIDE FULL ERROR MESSAGE FROM FAILED LINKED SERVICE CONNECTION>

I am trying to create a blob linked service, and I have the right account key, but it can't connect??
I know I have the correct account key.

Solution:
---------------------------
Customer is attempting to connect to an Azure Blob Store that has a firewall enabled and they are using an account key.
https://docs.microsoft.com/en-us/azure/data-factory/connector-azure-blob-storage#linked-service-properties

This is not allowed at this time and they will not be able to connect.

There are several possible solutions:
1. Use a self-hosted IR and add the ip address of the IR to the firewall.
2. Changed the identity type to a managed identitity and leave the firewall as is.
3. Remove the firewall from the blob store. (Not an acceptable solution though. This will work, but push for keeping the firewall.)

Skills we're looking for:
---------------------------
They should gather some further information from the customer either in a call or through email to realize what settings
are in place in the linked service and blob store.

They should also eventually provide the link posted above and know that the settings the customer has in place 
won't work.

If they recommend removing the firewall, push them that the customer wants/needs the firewall until they arrive at another solution.


Scenario 3
======================================================================
Description:
---------------------------
Customer Verbatim:
---------------------------
Solution:
---------------------------
Skills we're looking for:
---------------------------

Scenario 4
======================================================================
Description:
---------------------------
Customer wants to make a pipeline that uses a copy activity to read a name from a file using a 'Lookup' activity
and then the sink folder of the copy activity should be dynamically created using that name.

So lookup is reading a file, and the Copy Activity is pulling the output from Lookup to dynamically name the folder.
In this instance, we want the folder to be named the first value in the first column of the folder,
which is "puppy".

Be sure to attach full copy activity support files on the case so the engineer can attempt to repro.

Customer Verbatim:
---------------------------

Operation on target Copy data1 failed: Failed to convert the value in 'folderPath' property to 'System.String' type. Please make sure the payload structure and value are correct. 


I have a pipeline that is creating a folder from the text in the source file, but its failing with a super weird error.
My Pipeline details are attached!

Solution:
---------------------------

The expression for the FolderName parameter is incorrect and should be:
	
@activity('Lookup1').output.firstRow.Prop_0

Skills we're looking for:
---------------------------
1. Understand how to see the Output of the lookup
2. Understanding how to use this output to correctly define the expression needed.